{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Langchain Fundamentals"
      ],
      "metadata": {
        "id": "v-g27EnviC5J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGeMXriR26su"
      },
      "outputs": [],
      "source": [
        "pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai"
      ],
      "metadata": {
        "id": "BeTyQiy73Y9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"YOUR_API_KEY\""
      ],
      "metadata": {
        "id": "TIMHm8zc3nFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "FKtyk1bz3u34"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.9)"
      ],
      "metadata": {
        "id": "26iwhaac35NY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"What are 5 vacation destinations for someone who likes to eat pasta?\"\n",
        "print(llm(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IufpwIjF3_oZ",
        "outputId": "57eaa9b9-6802-44cd-9333-282f296d5c41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Rome, Italy\n",
            "2. Bologna, Italy\n",
            "3. Florence, Italy\n",
            "4. Venice, Italy\n",
            "5. Naples, Italy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "_FrVf_uS4Cpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"food\"],\n",
        "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
        ")"
      ],
      "metadata": {
        "id": "wFbOtGqR4F2x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(prompt.format(food=\"Paneer\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axXwyYjO4MzY",
        "outputId": "d27a09e3-7407-47e7-a085-b658a7b79f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What are 5 vacation destinations for someone who likes to eat Paneer?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(llm(prompt.format(food=\"Paneer\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUKZPpIx4Sqb",
        "outputId": "21b2a715-864c-48bb-aee1-d1f55cb04c26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. New Delhi, India \n",
            "2. Jaipur, India \n",
            "3. Agra, India\n",
            "4. Chandigarh, India \n",
            "5. Amritsar, India\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain"
      ],
      "metadata": {
        "id": "pgvuCMmq4exq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0.9)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"food\"],\n",
        "    template=\"What are 5 vacation destinations for someone who likes to eat {food}?\",\n",
        ")"
      ],
      "metadata": {
        "id": "O0CYJw4u7Uxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "44rbaiag7a3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(chain.run(\"Mangoes\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQmacUSO7da6",
        "outputId": "66805f0c-e3f9-4e2d-9b25-db919142ff7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "1. Goa, India\n",
            "2. Mauritius\n",
            "3. Bali, Indonesia\n",
            "4. Dominican Republic\n",
            "5. Guyana\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using OpenAI API with SerpAPI"
      ],
      "metadata": {
        "id": "T2bdtWyyiJMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-search-results"
      ],
      "metadata": {
        "id": "N1TNkMPt9d8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import load_tools\n",
        "from langchain.agents import initialize_agent\n",
        "from langchain.llms import OpenAI"
      ],
      "metadata": {
        "id": "7qc1KCji-RQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "pKEwKfys-TDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"SERPAPI_API_KEY\"] = \"7350d7d9c7bc823012884982e41b4a62ee3f56771735ce7d41e8a30bcc34d02d\"\n",
        "tools = load_tools([\"serpapi\", \"llm-math\"], llm=llm)"
      ],
      "metadata": {
        "id": "P2hJtmm0-W0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=\"zero-shot-react-description\", verbose=True)"
      ],
      "metadata": {
        "id": "QV12t7s3-e8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"Who is the current captain of the Argentina Football team? What is the largest prime number that is smaller than their age?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "ztQ17aqt-1_z",
        "outputId": "ed52c62b-e0d9-4d6f-c3c8-6864c533755e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m I need to find out who the captain is and their age.\n",
            "Action: Search\n",
            "Action Input: \"Argentina Football team captain\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mCaptained by Diego Maradona, Argentina won their second World Cup eight years later, in 1986, with a 3–2 final victory over West Germany. They reached the final ...\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to find out the age of the captain.\n",
            "Action: Search\n",
            "Action Input: \"Diego Maradona age\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m60 years\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I need to use the calculator to find the largest prime number that is smaller than 60.\n",
            "Action: Calculator\n",
            "Action Input: 60\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAnswer: 60\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer.\n",
            "Final Answer: The current captain of the Argentina Football team is Diego Maradona, and the largest prime number that is smaller than his age is 59.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The current captain of the Argentina Football team is Diego Maradona, and the largest prime number that is smaller than his age is 59.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, ConversationChain"
      ],
      "metadata": {
        "id": "OcVKPrPUAI8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0)\n",
        "conversation = ConversationChain(llm=llm, verbose=True)"
      ],
      "metadata": {
        "id": "PQRjA0xAAMqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Hi there!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "z2gLmJXiAVAX",
        "outputId": "525d0100-e9ff-458c-fa2a-5e21d04570f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Human: Hi there!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Hi there! It's nice to meet you. My name is AI. What's your name?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"My name is Kartik!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 292
        },
        "id": "_LDxSgNYAXcP",
        "outputId": "cd37e64a-1109-4b80-fc42-2334f969646e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
            "Human: My name is Kartik!\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Nice to meet you, Kartik! What can I do for you today?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Could you tell me when is the next ICC Men's Cricket world cup?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "BAsH2dWTAgoY",
        "outputId": "4792adab-6969-4abc-a028-c52a6b9e05e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
            "Human: My name is Kartik!\n",
            "AI:  Nice to meet you, Kartik! What can I do for you today?\n",
            "Human: Could you tell me when is the next ICC Men's Cricket world cup?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Sure, the next ICC Men's Cricket World Cup is scheduled to take place in India in October and November of 2023.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Who is going to captain India?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "Mr4tufkvAqHY",
        "outputId": "4f3e81fe-7975-4105-dff0-8dd58ce3326e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
            "Human: My name is Kartik!\n",
            "AI:  Nice to meet you, Kartik! What can I do for you today?\n",
            "Human: Could you tell me when is the next ICC Men's Cricket world cup?\n",
            "AI:  Sure, the next ICC Men's Cricket World Cup is scheduled to take place in India in October and November of 2023.\n",
            "Human: Who is going to captain India?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"  The current captain of the Indian cricket team is Virat Kohli. He is expected to remain the captain for the 2023 ICC Men's Cricket World Cup.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"What was my name?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "id": "NzEGqUJ1AxzA",
        "outputId": "5b56bdbf-f5fc-48b2-9935-22a61bbb1d55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
            "Human: My name is Kartik!\n",
            "AI:  Nice to meet you, Kartik! What can I do for you today?\n",
            "Human: Could you tell me when is the next ICC Men's Cricket world cup?\n",
            "AI:  Sure, the next ICC Men's Cricket World Cup is scheduled to take place in India in October and November of 2023.\n",
            "Human: Who is going to captain India?\n",
            "AI:   The current captain of the Indian cricket team is Virat Kohli. He is expected to remain the captain for the 2023 ICC Men's Cricket World Cup.\n",
            "Human: What was my name?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Your name is Kartik.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"What was the first thing i asked you today?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "sMPSB-bCA1Ow",
        "outputId": "ce007633-3a96-477a-fa5b-2e61611bae69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
            "Human: My name is Kartik!\n",
            "AI:  Nice to meet you, Kartik! What can I do for you today?\n",
            "Human: Could you tell me when is the next ICC Men's Cricket world cup?\n",
            "AI:  Sure, the next ICC Men's Cricket World Cup is scheduled to take place in India in October and November of 2023.\n",
            "Human: Who is going to captain India?\n",
            "AI:   The current captain of the Indian cricket team is Virat Kohli. He is expected to remain the captain for the 2023 ICC Men's Cricket World Cup.\n",
            "Human: What was my name?\n",
            "AI:  Your name is Kartik.\n",
            "Human: What was the first thing i asked you today?\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"  You asked me when is the next ICC Men's Cricket World Cup.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation.predict(input=\"Translate the first thing i said to you in hindi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "XPeEr3EoBNLr",
        "outputId": "b69e0b6b-7a57-4b2b-f5a6-e969bef37cae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
            "\n",
            "Current conversation:\n",
            "Human: Hi there!\n",
            "AI:  Hi there! It's nice to meet you. My name is AI. What's your name?\n",
            "Human: My name is Kartik!\n",
            "AI:  Nice to meet you, Kartik! What can I do for you today?\n",
            "Human: Could you tell me when is the next ICC Men's Cricket world cup?\n",
            "AI:  Sure, the next ICC Men's Cricket World Cup is scheduled to take place in India in October and November of 2023.\n",
            "Human: Who is going to captain India?\n",
            "AI:   The current captain of the Indian cricket team is Virat Kohli. He is expected to remain the captain for the 2023 ICC Men's Cricket World Cup.\n",
            "Human: What was my name?\n",
            "AI:  Your name is Kartik.\n",
            "Human: What was the first thing i asked you today?\n",
            "AI:   You asked me when is the next ICC Men's Cricket World Cup.\n",
            "Human: Your answer regarding the captain of India is incorrect\n",
            "AI:  I apologize for the incorrect information. The current captain of the Indian cricket team is Virat Kohli, but it is possible that this could change before the 2023 ICC Men's Cricket World Cup.\n",
            "Human: The current captain is Rohit Sharma\n",
            "AI:   You are correct. The current captain of the Indian cricket team is Rohit Sharma.\n",
            "Human: Translate the first thing i said to you in hindi\n",
            "AI:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  The first thing you said to me was \"Hi there!\" in English. In Hindi, that would be \"Namaste!\"'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chat functionality Langchain"
      ],
      "metadata": {
        "id": "1gLmtRpfiQI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage\n",
        "\n",
        "chat = ChatOpenAI(temperature=1)"
      ],
      "metadata": {
        "id": "2I5TuJhiFty_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat(\n",
        "    [\n",
        "        SystemMessage(content=\"You are an Unhelpful AI bot that makes jokes on whatever the user inputs\"),\n",
        "        HumanMessage(content=\"I would like to go to New York, how should I do this?\")\n",
        "\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCgWzrSuKL7a",
        "outputId": "2d36cb4b-f6e9-4559-ccd6-e6f8ba432a24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content=\"Well, you can start by putting one foot in front of the other. But good luck, because according to my calculations, it's going to take you approximately forever to get there.\", additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ChatMessageHistory\n",
        "\n",
        "chat = ChatOpenAI(temperature=0)\n",
        "history = ChatMessageHistory()\n",
        "history.add_ai_message(\"Hi\")\n",
        "history.add_user_message(\"What is the capital of Pakistan?\")"
      ],
      "metadata": {
        "id": "rgK_xQ4JlLGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKPEFysollxh",
        "outputId": "59ab1fdd-84ef-4cd0-c428-7a8543ca21ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='Hi', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='What is the capital of Pakistan?', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ai_response = chat(history.messages)\n",
        "ai_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUt6vUAgltGC",
        "outputId": "354a0a73-b400-4bc5-d212-f52d7009dd95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AIMessage(content='The capital of Pakistan is Islamabad.', additional_kwargs={}, example=False)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history.add_ai_message(ai_response.content)\n",
        "history.messages"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_5ScAQ2l4-d",
        "outputId": "79da5ec6-b590-45d3-8905-32cd53b9dd2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[AIMessage(content='Hi', additional_kwargs={}, example=False),\n",
              " HumanMessage(content='What is the capital of Pakistan?', additional_kwargs={}, example=False),\n",
              " AIMessage(content='The capital of Pakistan is Islamabad.', additional_kwargs={}, example=False)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import SimpleSequentialChain\n",
        "\n",
        "llm = OpenAI(temperature=1)"
      ],
      "metadata": {
        "id": "rmLsipt6qDGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Your job is to come up with a classic dish from the area that the users suggests.\n",
        "{user_location}\n",
        "\n",
        "YOUR RESPONSE:\n",
        "\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"user_location\"], template=template)\n",
        "\n",
        "location_chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "GwZXm1qyqZ7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Given a meal, give a short and simple recipe on how to make that dish at home.\n",
        "{user_meal}\n",
        "\n",
        "YOUR RESPONSE:\n",
        "\"\"\"\n",
        "prompt_template = PromptTemplate(input_variables=[\"user_meal\"], template=template)\n",
        "\n",
        "meal_chain = LLMChain(llm=llm, prompt=prompt_template)"
      ],
      "metadata": {
        "id": "VPNiK92pqehG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "overall_chain = SimpleSequentialChain(chains=[location_chain, meal_chain], verbose=True)"
      ],
      "metadata": {
        "id": "fKTV7fHBqji7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review = overall_chain.run(\"U.S.A\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUFW7pdBqmTD",
        "outputId": "89e0a605-1b28-4e70-b101-31a4d367ecf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[36;1m\u001b[1;3mClassic American dish: Macaroni and Cheese.\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m\n",
            "Macaroni and Cheese\n",
            "\n",
            "Ingredients: \n",
            "-4 cups uncooked elbow macaroni\n",
            "-3 tablespoons butter\n",
            "-3 tablespoons all-purpose flour\n",
            "-1 teaspoon salt\n",
            "-1/4 teaspoon freshly ground black pepper\n",
            "-3 cups warm milk\n",
            "-2 cups grated sharp cheddar cheese\n",
            "\n",
            "Instructions:\n",
            "1. Preheat the oven to 375 degrees Fahrenheit.\n",
            "2. Cook the macaroni according to the package instructions, then drain.\n",
            "3. In a large saucepan, melt the butter over medium heat.\n",
            "4. Add the flour, salt, and pepper, and stir until combined.\n",
            "5. Gradually add the milk, stirring constantly until it thickens.\n",
            "6. Remove from heat, then add the cheese and stir until melted.\n",
            "7. Combine the macaroni, cheese mixture, and 1/4 cup of the cheese, stirring until combined.\n",
            "8. Put the macaroni and cheese into a greased baking dish.\n",
            "9. Sprinkle the remaining cheese over the top.\n",
            "10. Bake for 25 minutes or until golden brown.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Langchain Use cases"
      ],
      "metadata": {
        "id": "vT_NBko8iVRw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w51kHjGrfhyQ",
        "outputId": "070f0c9d-d4d7-4cd2-def7-21f53a132385"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "openai_api_key = os.getenv('OPENAI_API_KEY', 'YOUR_API_KEY')"
      ],
      "metadata": {
        "id": "jObrMoE6fDi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarize Long Text - Out of scope of ChatGPT due to no.of tokens"
      ],
      "metadata": {
        "id": "DMQTqYEOgI8n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain # chain used to summarize long text\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "blQOQNzfgLMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('worked.txt', 'r') as file:\n",
        "    text = file.read()\n",
        "\n",
        "# Printing the first 285 characters as a preview\n",
        "print (text[:285])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XpT4gkpgYx_",
        "outputId": "f5326996-5ee5-46e6-bcce-420b5f80c4d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "February 2021Before college the two main things I worked on, outside of school,\n",
            "were writing and programming. I didn't write essays. I wrote what\n",
            "beginning writers were supposed to write then, and probably still\n",
            "are: short stories. My stories were awful. They had hardly any plot,\n",
            "just\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tiktoken"
      ],
      "metadata": {
        "id": "m_ImuaUgXlHv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_tokens = llm.get_num_tokens(text)\n",
        "\n",
        "print (f\"There are {num_tokens} tokens in your file\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBESjTGugeW3",
        "outputId": "d4484b5a-f1bb-4b6b-de0c-cd79d31858cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 17716 tokens in your file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dividing the large document into smaller chunks - finding summary of each chunk - Finding Summary of Summaries for final summary\n",
        "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\"], chunk_size=5000, chunk_overlap=350)\n",
        "docs = text_splitter.create_documents([text])\n",
        "\n",
        "print (f\"You now have {len(docs)} docs intead of 1 piece of text\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhwfVTCfgh4u",
        "outputId": "92c569ce-04b1-47fb-cb49-82ee8e617c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You now have 16 docs intead of 1 piece of text\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_summarize_chain(llm=llm, chain_type='map_reduce')"
      ],
      "metadata": {
        "id": "5eW1hXKegsTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = chain.run(docs)\n",
        "print (output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8kUnX8nguhO",
        "outputId": "aa958d4c-a312-4e4d-f2b7-369deee1cafc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " This essay is a reflection on the author's experience with writing and programming before college, his journey to becoming an artist, and his experience with founding Y Combinator. He discusses the difficulties of writing essays, the advantages of being independent-minded in fields affected by rapid change, and the difficulties of leaving Y Combinator. He also acknowledges the help of several people in reading drafts of the essay.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q/A using Documents - Using Embeddings"
      ],
      "metadata": {
        "id": "TxvQitjgTSdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI\n",
        "\n",
        "# The vectorstore we'll be using\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# The LangChain component we'll use to get the documents\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "# The easy document loader for text\n",
        "from langchain.document_loaders import TextLoader\n",
        "\n",
        "# The embedding engine that will convert our text to vectors\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "llm = OpenAI(temperature=0)"
      ],
      "metadata": {
        "id": "0xhB-KpXTXLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = TextLoader('worked.txt')\n",
        "doc = loader.load()\n",
        "print (f\"You have {len(doc)} document\")\n",
        "print (f\"You have {len(doc[0].page_content)} characters in that document\")"
      ],
      "metadata": {
        "id": "JUlGpCp7V67f",
        "outputId": "f6ba3852-2553-48a4-c2a6-dff8ab9a74e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 1 document\n",
            "You have 74663 characters in that document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=400)\n",
        "docs = text_splitter.split_documents(doc)"
      ],
      "metadata": {
        "id": "Db5wzMoGWavg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the total number of characters so we can see the average later\n",
        "num_total_characters = sum([len(x.page_content) for x in docs])\n",
        "\n",
        "print (f\"Now you have {len(docs)} documents that have an average of {num_total_characters / len(docs):,.0f} characters (smaller pieces)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXDPMD9zWwTQ",
        "outputId": "bad5ad64-239f-4f31-877f-f4043bf6d773"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now you have 29 documents that have an average of 2,930 characters (smaller pieces)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install faiss-cpu"
      ],
      "metadata": {
        "id": "0iU9245qfy5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI’s text embeddings measure the relatedness of text strings\n",
        "# Get your embeddings engine ready\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)\n",
        "\n",
        "# Embed your documents and combine with the raw text in a pseudo db. Note: This will make an API call to OpenAI\n",
        "docsearch = FAISS.from_documents(docs, embeddings)"
      ],
      "metadata": {
        "id": "iPT8VElkW_zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=docsearch.as_retriever())"
      ],
      "metadata": {
        "id": "ZM_MB5NJf8jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the difficulties the author faced in programming?\"\n",
        "qa.run(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "9Kr_lMXmf9on",
        "outputId": "24ba8171-3517-45f4-ed04-8f7a5c6529c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The author faced difficulties in programming due to the primitive programming languages available at the time, the lack of time-sharing machines with interactive OSes, and the complexity of the problem when writing an interpreter written in itself.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Querying Custom Tabular Data - SQL"
      ],
      "metadata": {
        "id": "poi9A1bKoMiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI, SQLDatabase, SQLDatabaseChain\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "mzoMAJSqoOnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sqlite_db_path = 'San_Francisco_Trees.db'\n",
        "db = SQLDatabase.from_uri(f\"sqlite:///{sqlite_db_path}\")"
      ],
      "metadata": {
        "id": "nf35KWwFpV9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_chain = SQLDatabaseChain(llm=llm, database=db, verbose=True)"
      ],
      "metadata": {
        "id": "Ua4tXKsKp3ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The SQLDatabase Chain is able to perform the following functions on our custom database\n",
        "\n",
        "# Find which table to use\n",
        "# Find which column to use\n",
        "# Construct the correct sql query\n",
        "# Execute that query\n",
        "# Get the result\n",
        "# Return a natural language reponse back\n",
        "\n",
        "db_chain.run(\"How many species of Trees are present?\")"
      ],
      "metadata": {
        "id": "3UC0bRQCp6F5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accessing data from a URL - API"
      ],
      "metadata": {
        "id": "k2cnjbgsU1CL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import APIChain\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "otD6Jx0uuD6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_docs = \"\"\"\n",
        "\n",
        "BASE URL: https://restcountries.com/\n",
        "\n",
        "API Documentation:\n",
        "\n",
        " /v3.1/name/{name}\n",
        "\n",
        " /v3.1/currency/{currency}\n",
        "\n",
        "Woo! This is my documentation - we can write anything here\n",
        "\"\"\"\n",
        "\n",
        "chain_new = APIChain.from_llm_and_api_docs(llm, api_docs, verbose=True)"
      ],
      "metadata": {
        "id": "SYrRMOZpuISo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain_new.run('Can you tell me information about India?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "ejD1fGtjuXjC",
        "outputId": "c837adc3-ed58-4b47-bc2c-5702f95fa36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/name/India\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"India\",\"official\":\"Republic of India\",\"nativeName\":{\"eng\":{\"official\":\"Republic of India\",\"common\":\"India\"},\"hin\":{\"official\":\"भारत गणराज्य\",\"common\":\"भारत\"},\"tam\":{\"official\":\"இந்தியக் குடியரசு\",\"common\":\"இந்தியா\"}}},\"tld\":[\".in\"],\"cca2\":\"IN\",\"ccn3\":\"356\",\"cca3\":\"IND\",\"cioc\":\"IND\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"INR\":{\"name\":\"Indian rupee\",\"symbol\":\"₹\"}},\"idd\":{\"root\":\"+9\",\"suffixes\":[\"1\"]},\"capital\":[\"New Delhi\"],\"altSpellings\":[\"IN\",\"Bhārat\",\"Republic of India\",\"Bharat Ganrajya\",\"இந்தியா\"],\"region\":\"Asia\",\"subregion\":\"Southern Asia\",\"languages\":{\"eng\":\"English\",\"hin\":\"Hindi\",\"tam\":\"Tamil\"},\"translations\":{\"ara\":{\"official\":\"جمهورية الهند\",\"common\":\"الهند\"},\"bre\":{\"official\":\"Republik India\",\"common\":\"India\"},\"ces\":{\"official\":\"Indická republika\",\"common\":\"Indie\"},\"cym\":{\"official\":\"Republic of India\",\"common\":\"India\"},\"deu\":{\"official\":\"Republik Indien\",\"common\":\"Indien\"},\"est\":{\"official\":\"India Vabariik\",\"common\":\"India\"},\"fin\":{\"official\":\"Intian tasavalta\",\"common\":\"Intia\"},\"fra\":{\"official\":\"République de l'Inde\",\"common\":\"Inde\"},\"hrv\":{\"official\":\"Republika Indija\",\"common\":\"Indija\"},\"hun\":{\"official\":\"Indiai Köztársaság\",\"common\":\"India\"},\"ita\":{\"official\":\"Repubblica dell'India\",\"common\":\"India\"},\"jpn\":{\"official\":\"インド共和国\",\"common\":\"インド\"},\"kor\":{\"official\":\"인도 공화국\",\"common\":\"인도\"},\"nld\":{\"official\":\"Republiek India\",\"common\":\"India\"},\"per\":{\"official\":\"جمهوری هندوستان\",\"common\":\"هند\"},\"pol\":{\"official\":\"Republika Indii\",\"common\":\"Indie\"},\"por\":{\"official\":\"República da Índia\",\"common\":\"Índia\"},\"rus\":{\"official\":\"Республика Индия\",\"common\":\"Индия\"},\"slk\":{\"official\":\"Indická republika\",\"common\":\"India\"},\"spa\":{\"official\":\"República de la India\",\"common\":\"India\"},\"srp\":{\"official\":\"Република Индија\",\"common\":\"Индија\"},\"swe\":{\"official\":\"Republiken Indien\",\"common\":\"Indien\"},\"tur\":{\"official\":\"Hindistan Cumhuriyeti\",\"common\":\"Hindistan\"},\"urd\":{\"official\":\"جمہوریہ بھارت\",\"common\":\"بھارت\"},\"zho\":{\"official\":\"印度共和国\",\"common\":\"印度\"}},\"latlng\":[20.0,77.0],\"landlocked\":false,\"borders\":[\"BGD\",\"BTN\",\"MMR\",\"CHN\",\"NPL\",\"PAK\"],\"area\":3287590.0,\"demonyms\":{\"eng\":{\"f\":\"Indian\",\"m\":\"Indian\"},\"fra\":{\"f\":\"Indienne\",\"m\":\"Indien\"}},\"flag\":\"\\uD83C\\uDDEE\\uD83C\\uDDF3\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/WSk3fLwG4vtPQetp7\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/304716\"},\"population\":1380004385,\"gini\":{\"2011\":35.7},\"fifa\":\"IND\",\"car\":{\"signs\":[\"IND\"],\"side\":\"left\"},\"timezones\":[\"UTC+05:30\"],\"continents\":[\"Asia\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/in.png\",\"svg\":\"https://flagcdn.com/in.svg\",\"alt\":\"The flag of India is composed of three equal horizontal bands of saffron, white and green. A navy blue wheel with twenty-four spokes — the Ashoka Chakra — is centered in the white band.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/in.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/in.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[28.6,77.2]},\"postalCode\":{\"format\":\"######\",\"regex\":\"^(\\\\d{6})$\"}},{\"name\":{\"common\":\"British Indian Ocean Territory\",\"official\":\"British Indian Ocean Territory\",\"nativeName\":{\"eng\":{\"official\":\"British Indian Ocean Territory\",\"common\":\"British Indian Ocean Territory\"}}},\"tld\":[\".io\"],\"cca2\":\"IO\",\"ccn3\":\"086\",\"cca3\":\"IOT\",\"independent\":false,\"status\":\"officially-assigned\",\"unMember\":false,\"currencies\":{\"USD\":{\"name\":\"United States dollar\",\"symbol\":\"$\"}},\"idd\":{\"root\":\"+2\",\"suffixes\":[\"46\"]},\"capital\":[\"Diego Garcia\"],\"altSpellings\":[\"IO\"],\"region\":\"Africa\",\"subregion\":\"Eastern Africa\",\"languages\":{\"eng\":\"English\"},\"translations\":{\"ara\":{\"official\":\"إقليم المحيط الهندي البريطاني\",\"common\":\"إقليم المحيط الهندي البريطاني\"},\"bre\":{\"official\":\"Tiriad breizhveurat Meurvor Indez\",\"common\":\"Tiriad breizhveurat Meurvor Indez\"},\"ces\":{\"official\":\"Britské indickooceánské území\",\"common\":\"Britské indickooceánské území\"},\"cym\":{\"official\":\"Tiriogaeth Brydeinig Cefnfor India\",\"common\":\"Tiriogaeth Brydeinig Cefnfor India\"},\"deu\":{\"official\":\"Britisches Territorium im Indischen Ozean\",\"common\":\"Britisches Territorium im Indischen Ozean\"},\"est\":{\"official\":\"Briti India ookeani ala\",\"common\":\"Briti India ookeani ala\"},\"fin\":{\"official\":\"Brittiläinen Intian valtameren alue\",\"common\":\"Brittiläinen Intian valtameren alue\"},\"fra\":{\"official\":\"Territoire britannique de l' océan Indien\",\"common\":\"Territoire britannique de l'océan Indien\"},\"hrv\":{\"official\":\"British Indian Ocean Territory\",\"common\":\"Britanski Indijskooceanski teritorij\"},\"hun\":{\"official\":\"Brit Indiai-óceáni Terület\",\"common\":\"Brit Indiai-óceáni Terület\"},\"ita\":{\"official\":\"Territorio britannico dell'Oceano Indiano\",\"common\":\"Territorio britannico dell'oceano indiano\"},\"jpn\":{\"official\":\"イギリス領インド洋地域\",\"common\":\"イギリス領インド洋地域\"},\"kor\":{\"official\":\"인도 공화국\",\"common\":\"인도\"},\"nld\":{\"official\":\"Brits Indische Oceaan Territorium\",\"common\":\"Britse Gebieden in de Indische Oceaan\"},\"per\":{\"official\":\"قلمرو بریتانیا در اقیانوس هند\",\"common\":\"قلمرو بریتانیا در اقیانوس هند\"},\"pol\":{\"official\":\"Brytyjskie Terytorium Oceanu Indyjskiego\",\"common\":\"Brytyjskie Terytorium Oceanu Indyjskiego\"},\"por\":{\"official\":\"British Indian Ocean Territory\",\"common\":\"Território Britânico do Oceano Índico\"},\"rus\":{\"official\":\"Британская территория Индийского океана\",\"common\":\"Британская территория в Индийском океане\"},\"slk\":{\"official\":\"Britské indickooceánske územie\",\"common\":\"Britské indickooceánske územie\"},\"spa\":{\"official\":\"Territorio Británico del Océano Índico\",\"common\":\"Territorio Británico del Océano Índico\"},\"srp\":{\"official\":\"Британска територија Индијског океана\",\"common\":\"Британска територија Индијског океана\"},\"swe\":{\"official\":\"Brittiska territoriet i Indiska Oceanen\",\"common\":\"Brittiska territoriet i Indiska Oceanen\"},\"tur\":{\"official\":\"Britanya Hint Okyanusu Toprakları\",\"common\":\"Britanya Hint Okyanusu Toprakları\"},\"urd\":{\"official\":\"برطانوی بحرہند خطہ\",\"common\":\"برطانوی بحرہند خطہ\"},\"zho\":{\"official\":\"英属印度洋领地\",\"common\":\"英属印度洋领地\"}},\"latlng\":[-6.0,71.5],\"landlocked\":false,\"area\":60.0,\"demonyms\":{\"eng\":{\"f\":\"Indian\",\"m\":\"Indian\"}},\"flag\":\"\\uD83C\\uDDEE\\uD83C\\uDDF4\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/bheNucgekVEYozoi6\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/1993867\"},\"population\":3000,\"car\":{\"signs\":[\"GB\"],\"side\":\"right\"},\"timezones\":[\"UTC+06:00\"],\"continents\":[\"Asia\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/io.png\",\"svg\":\"https://flagcdn.com/io.svg\"},\"coatOfArms\":{},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[-7.3,72.4]}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' India is a country located in Southern Asia, with a population of over 1.38 billion people. It has a capital city of New Delhi, and its official language is English. The currency used in India is the Indian rupee (₹). India is bordered by Bangladesh, Bhutan, Myanmar, China, Nepal, and Pakistan.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain_new.run('Can you tell me about the currency INR?')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "rmXEPETuueob",
        "outputId": "e22e4dc2-200b-4a94-bf49-4de5e67434db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m https://restcountries.com/v3.1/currency/INR\u001b[0m\n",
            "\u001b[33;1m\u001b[1;3m[{\"name\":{\"common\":\"Bhutan\",\"official\":\"Kingdom of Bhutan\",\"nativeName\":{\"dzo\":{\"official\":\"འབྲུག་རྒྱལ་ཁབ་\",\"common\":\"འབྲུག་ཡུལ་\"}}},\"tld\":[\".bt\"],\"cca2\":\"BT\",\"ccn3\":\"064\",\"cca3\":\"BTN\",\"cioc\":\"BHU\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"BTN\":{\"name\":\"Bhutanese ngultrum\",\"symbol\":\"Nu.\"},\"INR\":{\"name\":\"Indian rupee\",\"symbol\":\"₹\"}},\"idd\":{\"root\":\"+9\",\"suffixes\":[\"75\"]},\"capital\":[\"Thimphu\"],\"altSpellings\":[\"BT\",\"Kingdom of Bhutan\"],\"region\":\"Asia\",\"subregion\":\"Southern Asia\",\"languages\":{\"dzo\":\"Dzongkha\"},\"translations\":{\"ara\":{\"official\":\"مملكة بوتان\",\"common\":\"بوتان\"},\"bre\":{\"official\":\"Rouantelezh Bhoutan\",\"common\":\"Bhoutan\"},\"ces\":{\"official\":\"Bhútánské království\",\"common\":\"Bhútán\"},\"cym\":{\"official\":\"Teyrnas Bhwtan\",\"common\":\"Bhwtan\"},\"deu\":{\"official\":\"Königreich Bhutan\",\"common\":\"Bhutan\"},\"est\":{\"official\":\"Bhutani Kuningriik\",\"common\":\"Bhutan\"},\"fin\":{\"official\":\"Bhutanin kuningaskunta\",\"common\":\"Bhutan\"},\"fra\":{\"official\":\"Royaume du Bhoutan\",\"common\":\"Bhoutan\"},\"hrv\":{\"official\":\"Kraljevina Butan\",\"common\":\"Butan\"},\"hun\":{\"official\":\"Bhutáni Királyság\",\"common\":\"Bhután\"},\"ita\":{\"official\":\"Regno del Bhutan\",\"common\":\"Bhutan\"},\"jpn\":{\"official\":\"ブータン王国\",\"common\":\"ブータン\"},\"kor\":{\"official\":\"부탄 왕국\",\"common\":\"부탄\"},\"nld\":{\"official\":\"Koninkrijk Bhutan\",\"common\":\"Bhutan\"},\"per\":{\"official\":\"پادشاهی بوتان\",\"common\":\"بوتان\"},\"pol\":{\"official\":\"Bhutan\",\"common\":\"Bhutan\"},\"por\":{\"official\":\"Reino do Butão\",\"common\":\"Butão\"},\"rus\":{\"official\":\"Королевство Бутан\",\"common\":\"Бутан\"},\"slk\":{\"official\":\"Bhutánske krâľovstvo\",\"common\":\"Bhután\"},\"spa\":{\"official\":\"Reino de Bután\",\"common\":\"Bután\"},\"srp\":{\"official\":\"Краљевина Бутан\",\"common\":\"Бутан\"},\"swe\":{\"official\":\"Konungariket Bhutan\",\"common\":\"Bhutan\"},\"tur\":{\"official\":\"Butan Krallığı\",\"common\":\"Butan\"},\"urd\":{\"official\":\"سلطنت بھوٹان\",\"common\":\"بھوٹان\"},\"zho\":{\"official\":\"不丹王国\",\"common\":\"不丹\"}},\"latlng\":[27.5,90.5],\"landlocked\":true,\"borders\":[\"CHN\",\"IND\"],\"area\":38394.0,\"demonyms\":{\"eng\":{\"f\":\"Bhutanese\",\"m\":\"Bhutanese\"},\"fra\":{\"f\":\"Bhoutanaise\",\"m\":\"Bhoutanais\"}},\"flag\":\"\\uD83C\\uDDE7\\uD83C\\uDDF9\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/VEfXXBftTFLUpNgp8\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/184629\"},\"population\":771612,\"gini\":{\"2017\":37.4},\"fifa\":\"BHU\",\"car\":{\"signs\":[\"BHT\"],\"side\":\"left\"},\"timezones\":[\"UTC+06:00\"],\"continents\":[\"Asia\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/bt.png\",\"svg\":\"https://flagcdn.com/bt.svg\",\"alt\":\"The flag of Bhutan is divided diagonally, from the lower hoist-side corner to the upper fly-side corner, into an upper yellow and a lower orange triangle. A fly-side facing white dragon holding four jewels in its claws is situated along the boundary of the two triangles.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/bt.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/bt.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[27.47,89.63]}},{\"name\":{\"common\":\"India\",\"official\":\"Republic of India\",\"nativeName\":{\"eng\":{\"official\":\"Republic of India\",\"common\":\"India\"},\"hin\":{\"official\":\"भारत गणराज्य\",\"common\":\"भारत\"},\"tam\":{\"official\":\"இந்தியக் குடியரசு\",\"common\":\"இந்தியா\"}}},\"tld\":[\".in\"],\"cca2\":\"IN\",\"ccn3\":\"356\",\"cca3\":\"IND\",\"cioc\":\"IND\",\"independent\":true,\"status\":\"officially-assigned\",\"unMember\":true,\"currencies\":{\"INR\":{\"name\":\"Indian rupee\",\"symbol\":\"₹\"}},\"idd\":{\"root\":\"+9\",\"suffixes\":[\"1\"]},\"capital\":[\"New Delhi\"],\"altSpellings\":[\"IN\",\"Bhārat\",\"Republic of India\",\"Bharat Ganrajya\",\"இந்தியா\"],\"region\":\"Asia\",\"subregion\":\"Southern Asia\",\"languages\":{\"eng\":\"English\",\"hin\":\"Hindi\",\"tam\":\"Tamil\"},\"translations\":{\"ara\":{\"official\":\"جمهورية الهند\",\"common\":\"الهند\"},\"bre\":{\"official\":\"Republik India\",\"common\":\"India\"},\"ces\":{\"official\":\"Indická republika\",\"common\":\"Indie\"},\"cym\":{\"official\":\"Republic of India\",\"common\":\"India\"},\"deu\":{\"official\":\"Republik Indien\",\"common\":\"Indien\"},\"est\":{\"official\":\"India Vabariik\",\"common\":\"India\"},\"fin\":{\"official\":\"Intian tasavalta\",\"common\":\"Intia\"},\"fra\":{\"official\":\"République de l'Inde\",\"common\":\"Inde\"},\"hrv\":{\"official\":\"Republika Indija\",\"common\":\"Indija\"},\"hun\":{\"official\":\"Indiai Köztársaság\",\"common\":\"India\"},\"ita\":{\"official\":\"Repubblica dell'India\",\"common\":\"India\"},\"jpn\":{\"official\":\"インド共和国\",\"common\":\"インド\"},\"kor\":{\"official\":\"인도 공화국\",\"common\":\"인도\"},\"nld\":{\"official\":\"Republiek India\",\"common\":\"India\"},\"per\":{\"official\":\"جمهوری هندوستان\",\"common\":\"هند\"},\"pol\":{\"official\":\"Republika Indii\",\"common\":\"Indie\"},\"por\":{\"official\":\"República da Índia\",\"common\":\"Índia\"},\"rus\":{\"official\":\"Республика Индия\",\"common\":\"Индия\"},\"slk\":{\"official\":\"Indická republika\",\"common\":\"India\"},\"spa\":{\"official\":\"República de la India\",\"common\":\"India\"},\"srp\":{\"official\":\"Република Индија\",\"common\":\"Индија\"},\"swe\":{\"official\":\"Republiken Indien\",\"common\":\"Indien\"},\"tur\":{\"official\":\"Hindistan Cumhuriyeti\",\"common\":\"Hindistan\"},\"urd\":{\"official\":\"جمہوریہ بھارت\",\"common\":\"بھارت\"},\"zho\":{\"official\":\"印度共和国\",\"common\":\"印度\"}},\"latlng\":[20.0,77.0],\"landlocked\":false,\"borders\":[\"BGD\",\"BTN\",\"MMR\",\"CHN\",\"NPL\",\"PAK\"],\"area\":3287590.0,\"demonyms\":{\"eng\":{\"f\":\"Indian\",\"m\":\"Indian\"},\"fra\":{\"f\":\"Indienne\",\"m\":\"Indien\"}},\"flag\":\"\\uD83C\\uDDEE\\uD83C\\uDDF3\",\"maps\":{\"googleMaps\":\"https://goo.gl/maps/WSk3fLwG4vtPQetp7\",\"openStreetMaps\":\"https://www.openstreetmap.org/relation/304716\"},\"population\":1380004385,\"gini\":{\"2011\":35.7},\"fifa\":\"IND\",\"car\":{\"signs\":[\"IND\"],\"side\":\"left\"},\"timezones\":[\"UTC+05:30\"],\"continents\":[\"Asia\"],\"flags\":{\"png\":\"https://flagcdn.com/w320/in.png\",\"svg\":\"https://flagcdn.com/in.svg\",\"alt\":\"The flag of India is composed of three equal horizontal bands of saffron, white and green. A navy blue wheel with twenty-four spokes — the Ashoka Chakra — is centered in the white band.\"},\"coatOfArms\":{\"png\":\"https://mainfacts.com/media/images/coats_of_arms/in.png\",\"svg\":\"https://mainfacts.com/media/images/coats_of_arms/in.svg\"},\"startOfWeek\":\"monday\",\"capitalInfo\":{\"latlng\":[28.6,77.2]},\"postalCode\":{\"format\":\"######\",\"regex\":\"^(\\\\d{6})$\"}}]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' The Indian Rupee (INR) is the official currency of both Bhutan and India. It is represented by the symbol ₹.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chatbots"
      ],
      "metadata": {
        "id": "qNA7nqIRzLYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain import LLMChain\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "\n",
        "# Chat specific components - keep memory of conversation\n",
        "from langchain.memory import ConversationBufferMemory"
      ],
      "metadata": {
        "id": "Jtf2tBFzzMXT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "You are a chatbot that is an expert in the field of programming. Only generate code on user input and no other text unless asked upon. Do not type explanations.\n",
        "\n",
        "\n",
        "{chat_history}\n",
        "Human: {human_input}\n",
        "Chatbot:\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"chat_history\", \"human_input\"],\n",
        "    template=template\n",
        ")\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")"
      ],
      "metadata": {
        "id": "yoTUdSxozR2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain = LLMChain(\n",
        "    llm=OpenAI(openai_api_key=openai_api_key),\n",
        "    prompt=prompt,\n",
        "    verbose=True,\n",
        "    memory=memory\n",
        ")"
      ],
      "metadata": {
        "id": "VNhXddfQzlD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.predict(human_input=\"How do i write a code for Two sum on Leetcode in JAVA?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "-4w907J9zrdA",
        "outputId": "75c4dc65-155d-4530-eb36-84264e7e9857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a chatbot that is an expert in the field of programming. Only generate code on user input and no other text unless asked upon. Do not type explanations.\n",
            "\n",
            "\n",
            "\n",
            "Human: How do i write a code for Two sum on Leetcode in JAVA?\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' \\nclass Solution {\\n    public int[] twoSum(int[] nums, int target) {\\n        Map<Integer, Integer> map = new HashMap<>();\\n        for(int i = 0; i < nums.length; i++) {\\n            int complement = target - nums[i];\\n            if(map.containsKey(complement)) {\\n                return new int[] { map.get(complement), i };\\n            }\\n            map.put(nums[i], i);\\n        }\\n        throw new IllegalArgumentException(\"No two sum solution\");\\n    }\\n}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.predict(human_input=\"In which language did i ask you to write my code in?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "_AvANjw81J9K",
        "outputId": "83042d3c-505d-4163-f006-ae85b4db200e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a chatbot that is an expert in the field of programming. Only generate code on user input and no other text unless asked upon. Do not type explanations.\n",
            "\n",
            "\n",
            "Human: How do i write a code for Two sum on Leetcode in JAVA?\n",
            "AI:  \n",
            "class Solution {\n",
            "    public int[] twoSum(int[] nums, int target) {\n",
            "        Map<Integer, Integer> map = new HashMap<>();\n",
            "        for(int i = 0; i < nums.length; i++) {\n",
            "            int complement = target - nums[i];\n",
            "            if(map.containsKey(complement)) {\n",
            "                return new int[] { map.get(complement), i };\n",
            "            }\n",
            "            map.put(nums[i], i);\n",
            "        }\n",
            "        throw new IllegalArgumentException(\"No two sum solution\");\n",
            "    }\n",
            "}\n",
            "Human: In which language did i ask you to write my code in?\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' You asked me to write your code in Java.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.predict(human_input=\"On which platform did you search for my problem?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "6YNWct8c1q-S",
        "outputId": "c60c4b3a-65fc-45c7-f6c2-d59fc9613b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new  chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "You are a chatbot that is an expert in the field of programming. Only generate code on user input and no other text unless asked upon. Do not type explanations.\n",
            "\n",
            "\n",
            "Human: How do i write a code for Two sum on Leetcode in JAVA?\n",
            "AI:  \n",
            "class Solution {\n",
            "    public int[] twoSum(int[] nums, int target) {\n",
            "        Map<Integer, Integer> map = new HashMap<>();\n",
            "        for(int i = 0; i < nums.length; i++) {\n",
            "            int complement = target - nums[i];\n",
            "            if(map.containsKey(complement)) {\n",
            "                return new int[] { map.get(complement), i };\n",
            "            }\n",
            "            map.put(nums[i], i);\n",
            "        }\n",
            "        throw new IllegalArgumentException(\"No two sum solution\");\n",
            "    }\n",
            "}\n",
            "Human: In which language did i ask you to write my code in?\n",
            "AI:  You asked me to write your code in Java.\n",
            "Human: On which platform did you search for my problem?\n",
            "Chatbot:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' I searched for your problem on Leetcode.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizing Youtube Videos as Text\n"
      ],
      "metadata": {
        "id": "keCC3T_lW58A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import YoutubeLoader\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "#Used to get the transcript/text out of youtube url - youtube-transcript-api\n",
        "#python library to download videos from the internet - pythube"
      ],
      "metadata": {
        "id": "pyC6O4PxXMAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install youtube-transcript-api"
      ],
      "metadata": {
        "id": "TSUSrtyKYudm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytube"
      ],
      "metadata": {
        "id": "MoCHJn7jY78t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = YoutubeLoader.from_youtube_url(\"https://youtu.be/IqqHqDcXLww\", add_video_info=True)"
      ],
      "metadata": {
        "id": "WRB_s3u4ZClm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = loader.load()"
      ],
      "metadata": {
        "id": "exiiGN80ZFCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (type(result))\n",
        "print (f\"Found video from {result[0].metadata['author']} that is {result[0].metadata['length']} seconds long\")\n",
        "print (\"\")\n",
        "print (result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Edzrd8JlZHWs",
        "outputId": "3f1c003b-2d85-48fe-a304-9ae6822a80d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n",
            "Found video from Greg Kamradt (Data Indy) that is 470 seconds long\n",
            "\n",
            "[Document(page_content=\"hello good people and welcome to another tutorial where we are going to connect Google docs to open AI with Lang chain now why do we have to do this at all in the first place well you could imagine it would get pretty tedious copying and pasting your Google doc contents over to open Ai and in fact open AI has a character limit not a character limit a token limit where you can only put in certain amounts of information so if you want to do this at scale or you want to do it programmatically you're going to need the library to help you out with that and that library is going to be Lang chain now here you are Mr or Mrs or Miss cool person at your company and you're going to do a lot of really awesome business impact and the way you're going to do that is you're going to be connecting Lane chain with Google Drive and open AI so that you're able to summarize your documents and ask questions for them you could imagine these could be your product docs your user research interviews your internal knowledge base that your company is using or whatever may be so let's jump into some code and let's see what we're doing here but before we do that I want to set up our setup our documents so here I have a fictitious product document that I want to analyze with openai I have an introduction and our product is a Marketplace that connects startups employees who wants to sell vested Equity to buyers of secondary market shares so we want a way for employees to be able to sell their secondary market shares which is cool we have an introduction we have a problem statement and we have some cool products features and by the way this was all made via open AI a second document that we have is user interviews so we have one user interview here with a user named Sally and Eliza is going to be interviewing her so let's go over to the code and let's summarize these and ask some questions for them so the important part here and what enables this is a document loader that lane chain supports called Google Drive loader this means that you can go in you can initialize the class and then pass it a list of document IDs and these document IDs you can find up here in the URL up at the top in between a few of these forward slashes and with those you can pass a list of these document IDs to this parameter and the cool part about this too is I've already opened up the documentation you can also pass a folder ID so if you have a whole bunch of different files that you want to include in there now I'm only passing one but I'm still putting it in as a list and I'm passing my credentials for Google as well so here we got it ready we loaded it up and then now we actually call Dot load into these docs and so let's actually take a look at what docs looks like you can see here that we have all the text from that file that I just showed it's a little different format but no worries opening I can read it and if I were to take a look here if I were to do type docs it's just a list just a list of documents cool all right so now what I'm going to do is I'm going to load up my openai llm and I'm going to load in the load summary summarize chain all right we'll call that and then I'm going to call openai I pass my API K API key here in the background and I'm going to load summarize chain I'm going to pass in the language model that we want to use in this case openai the chain type we're going to do mapreduce today let me know if you want another tutorial on mapreduce and how those all work and I'm going to do verbose equals false here I'll show you what that means in a sec and then we'll call Dot run and so what this is going to do is this is going to summarize for us so let's wait and let's give it a second and then all of a sudden we get a summary about what our doc says which is the product dock that we had now if we wanted to see what was Lang Chang doing underneath the covers I'm going to say verbose equals true and then what you can see is kind of the logic that Lang chain is falling and how it's thinking so prompt after following what it does here is Lang Channel actually insert these words into there and say write a concise summary of the following and then we pass in all basically it's our dock that we had concise summary okay cool it knows that it's done and then it outputs that data to us which is cool now say we wanted to ask questions of this document well we need to load in a different chain in that case so I'm going to load in a QA chain here and I'm going to ask it a question which I'm going to store in a variable called query it doesn't matter what that's called and then I'm going to instantialize or initialize the chain with the llm and we have chain stuff we'll run that we're going to input our docs and give it our query between the two so all of a sudden I asked what problem is this product solving because all products should be solving a good problem this product is solving the problem of the lack of a viable secondary market for startup Equity sweet that's really cool that we are able to ask a question against our own personal document now another question which me takes a little bit more creativity they can't just regurgitate this from the dock how should we reach our target audience of this product let's go ahead and let's run this on here I for both equals false we should reach our target audience by leveraging digital marketing channels such as social media search engine etc etc you know I'm kind of interested to see what this one looked like behind the behind the covers here and so it looks like link chain actually inserts this into the prompt here use the following pieces of context to answer the questions at the end if you don't know the answer just say that you don't know just don't try to make up the answer so we have this right here and then all of a sudden they say question and helpful answer so underneath the covers here Lang chain is helping out with some prompt engineering to really optimize and streamline how we get extracted information from openai well there's also more right now we've just used one doc say you actually want to add two docs so in this case I am going to load up my document IDs of my second Google doc in this case it's going to be the user research interview that we saw beforehand I'm going to pass it my credentials then I'm going to load this into a new Doc and I'm actually just going to extend that list that we had beforehand with the new dock that we have so let's go ahead and run this okay cool and you know I want to show you what this looks like first off so we had our first stock up there and we have our second document right here so we have both these docs loaded up for us which is sweet and then what I'm going to do here is I'm going to say here's the query what are users actually saying about our product I'm going to load in the chain again and I'm going to pass our docs which now has two documents in there I'm going to load this in with our question in with a query and all of a sudden we get the users are saying the product is a good idea and that it could be helpful for startup employers who want to unlock the value of their financial goals so let's leave verbose equals true nope it's not on that one it's going to be on this call for both equals true let's see what's happening underneath the cover here so it looks like it's passing in a bunch of information cool actually passed in both docs in this case and passed in the second interview okay cool and user saying so we get our answer right there um so just to productionalize this a little bit more for you let's take a look I showed you that this uh docs variable is a list we'll say you wanted to removed one of them the way that I would do that is you could simply just do docs dot uh you could pop and so you could pop the last one off and you can see here there's only one left but if you wanted to programmatically make sure that you were selecting the right one well then here I'm just pulling off the first um document and I'm pulling out the dict to see what the parameters are we have the page content but then down here we also have some metadata about the document as well so we can understand which document we are removing there so cool now if you want help with this on your business please let me know I'd love to strategize about how we can make this happen here and I'm super curious to see the other applications that would be valuable to you so please let me know either comment or hit me up via email and we'll have some fun I'll see you later\", metadata={'source': 'IqqHqDcXLww', 'title': 'LangChain101: Connect Google Drive Files To OpenAI', 'description': 'Unknown', 'view_count': 22391, 'thumbnail_url': 'https://i.ytimg.com/vi/IqqHqDcXLww/hqdefault.jpg?sqp=-oaymwEXCJADEOABSFryq4qpAwkIARUAAIhCGAE=&rs=AOn4CLBT9UWD4duRwlPTaZ3nH8izoO74yA', 'publish_date': '2023-02-21 00:00:00', 'length': 470, 'author': 'Greg Kamradt (Data Indy)'})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "5ToRoKW2Znit"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_summarize_chain(llm, chain_type=\"stuff\", verbose=False)\n",
        "chain.run(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "7pDpRyjqZtpl",
        "outputId": "6e6adf67-17ef-4749-bb57-6ec23679116e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' In this tutorial, we learn how to connect Google Docs to Open AI with Lang Chain. This allows us to summarize documents and ask questions for them programmatically. We use the Google Drive Loader to pass a list of document IDs to the Lang Chain library, and then use the Open AI LM to summarize and ask questions. We can also use the verbose parameter to see the logic behind the Lang Chain.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For longer Youtube videos(In excess of OpenAI tokens)"
      ],
      "metadata": {
        "id": "X58Ghc2wbDep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loader = YoutubeLoader.from_youtube_url(\"https://youtu.be/rzA7UJ-hQn4\", add_video_info=True)"
      ],
      "metadata": {
        "id": "reQ-WlSrbIKT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = loader.load()"
      ],
      "metadata": {
        "id": "xk9aRjZ0baQI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# When large video is converted to text it exceeds 4097 token limit of OpenAI so we use summary of summaries\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "id": "9zukgomCbcr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=5000, chunk_overlap=0)"
      ],
      "metadata": {
        "id": "BgFWygwWbj93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = text_splitter.split_documents(result)"
      ],
      "metadata": {
        "id": "-Q-MlkfFbwMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = load_summarize_chain(llm, chain_type=\"map_reduce\", verbose=False)\n",
        "chain.run(texts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "YIWPeLf_bzf3",
        "outputId": "84041d34-028b-454b-8298-79450053a7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' This video explains the Collection Framework in Java, which includes data structures and algorithms to save time and effort. It also explains the benefits of the Collection Framework and how it is used in interviews and contests. It explains the use of ArrayList, Stack, Queue, Priority Queue, Array Deque, and Set, as well as how to use the add, remove, clear, set, and contains functions to manipulate an array list. It also explains how to traverse an array list, how to use the Stack class, and how to use the offer, poll, and peek functions of a queue. Finally, it reviews the different types of collections and frameworks available in Java.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Querying from a book"
      ],
      "metadata": {
        "id": "BYxKGWwKB9M5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "40VkpN1KCBZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader, PyPDFLoader\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import os"
      ],
      "metadata": {
        "id": "wuKqobNNCGwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"field-guide-to-data-science.pdf\")"
      ],
      "metadata": {
        "id": "CSG4fQ_hCLcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = loader.load()"
      ],
      "metadata": {
        "id": "zZOCv7-MCj36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'You have {len(data)} document(s) in your data')\n",
        "print (f'There are {len(data[30].page_content)} characters in your document')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clXBZ2IPCm6M",
        "outputId": "919713fe-a25b-45f5-bbd4-64d80ecebeda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You have 126 document(s) in your data\n",
            "There are 2812 characters in your document\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "mVMrYTKbDf2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print (f'Now you have {len(texts)} documents')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IC9HMlQoDhHH",
        "outputId": "151013c8-2b52-4f78-bc08-f15782469857"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now you have 162 documents\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Pinecone(Vector Database) to store our embeddings as Vectors for similarity search"
      ],
      "metadata": {
        "id": "SGd2b8zdENqj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pinecone-client"
      ],
      "metadata": {
        "id": "nwPIHnLfEWla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma, Pinecone\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "import pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nA7dsklRESex",
        "outputId": "3939d206-3d08-4587-f3a8-bce230f9ee44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', 'YOUR_PINECONE_API_KEY')\n",
        "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'us-west1-gcp-free')"
      ],
      "metadata": {
        "id": "PLL6kwkTE0Ta"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)"
      ],
      "metadata": {
        "id": "eGE_T2gfFLdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
        "    environment=PINECONE_API_ENV  # next to api key in console\n",
        ")\n",
        "index_name = \"langchaintest\" #index name present in pinecone"
      ],
      "metadata": {
        "id": "BUCto8wxFQ0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch = Pinecone.from_texts([t.page_content for t in texts], embeddings, index_name=index_name)"
      ],
      "metadata": {
        "id": "qPsombuzFsHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "T5RqbH4BhnpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ],
      "metadata": {
        "id": "dOuEX555hq_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")"
      ],
      "metadata": {
        "id": "b-uGf9Nfhtqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"What are the guiding principles of data science?\"\n",
        "docs = docsearch.similarity_search(query)"
      ],
      "metadata": {
        "id": "xlDS9UK6h0VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.run(input_documents=docs, question=query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "byJ-Sd7ch2ox",
        "outputId": "4b4a1373-f27a-4864-b0be-34743a864e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Be willing to fail, fail often and learn quickly, keep the goal in mind, dedication and focus lead to success, complicated does not equal better, reason and common sense are foundational, and embrace the discipline of writing.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    }
  ]
}